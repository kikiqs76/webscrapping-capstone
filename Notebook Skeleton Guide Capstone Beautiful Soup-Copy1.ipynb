{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Webscrapping using BeautifulSoup\n",
    "\n",
    "This notebook contains guidances & tasks on the data processing for the application\n",
    "\n",
    "(Please insert the background here )\n",
    "\n",
    "\n",
    "## Requesting the Data and Creating a BeautifulSoup\n",
    "\n",
    "Let's begin with requesting the web from the site with `get` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T05:12:23.275508Z",
     "start_time": "2020-01-13T05:12:20.009898Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url_get = requests.get('https://www.bi.go.id/id/statistik/indikator/data-inflasi.aspx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize what exactly you get from the `request.get`, we can use .content so ee what we exactly get, in here i slice it so it won't make our screen full of the html we get from the page. You can delete the slicing if you want to see what we fully get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T05:12:23.290648Z",
     "start_time": "2020-01-13T05:12:23.277650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n<!DOCTYPE html>\\r\\n<!--[if lt IE 9]>\\r\\n    <html class=\"no-js ie8 oldie\" lang=\\'en\\' xml:lang=\\'en\\'>\\r\\n<![endif]-->\\r\\n<!--[if gt IE 8]><!--> <html class=\"no-js\" lang=\\'en\\' xml:lang=\\'en\\'> <!--<![endif]-->\\r\\n<head><title>Indonesian Rupiah Exchange Rate - US Dollar - Historical Exchange Rates</title>\\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\\n<meta content=\"C#\" name=\"CODE_LANGUAGE\" />\\n<meta content=\"JavaScript\" name=\"vs_defaultClientScript\" />\\n<meta content=\"http://schemas.microsoft.com/intellisense/ie5\" name=\"vs_targetSchema\" />\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=5\">\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\\n\\n<meta name=\"mapping\" content=\"AP\" />\\n<base href=\"https://www.exchange-rates.org/\" />'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_get.content[1:777]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we get a very unstructured and complex html, which actually contains the codes needed to show the webpages on your web browser. But we as human still confused what and where we can use that piece of code, so here where we use the beautifulsoup. Beautiful soup class will result a beautifulsoup object. Beautiful Soup transforms a complex HTML document into a complex tree of Python objects. \n",
    "\n",
    "Let's make Beautiful soup object and feel free to explore the object here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T05:12:23.808122Z",
     "start_time": "2020-01-13T05:12:23.292610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "\n",
    "soup = BeautifulSoup(url_get.content,\"html.parser\")\n",
    "print(type(soup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the right key to scrap the data & Extracting the right information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the key and put the key into the `.find()` Put all the exploring the right key at this cell. (please change this markdown with your explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T05:12:23.878904Z",
     "start_time": "2020-01-13T05:12:23.854974Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'prettify'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-29f803aeea10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprettify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'prettify'"
     ]
    }
   ],
   "source": [
    "table = soup.find(...)\n",
    "print(table.prettify()[1:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the scrapping process here (please change this markdown with your explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T05:12:24.008256Z",
     "start_time": "2020-01-13T05:12:23.980358Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = [] #initiating a tuple\n",
    "\n",
    "for i in range(1, len(tr)):\n",
    "\n",
    "    #scrapping process\n",
    "    \n",
    "temp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data frame & Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the array into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T05:12:41.517372Z",
     "start_time": "2020-01-13T05:12:29.130015Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(...)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the data cleaning here (please change this markdown with your explanation of what you do for data wrangling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T05:12:59.165559Z",
     "start_time": "2020-01-13T05:12:58.910012Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing your webscrapping to the flask dashboard\n",
    "\n",
    "- Copy paste all of your web scrapping process to the desired position on the `app.py`\n",
    "- Changing the title of the dasboard at `index.html`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finishing This Notebook with Your Analysis and Conclusion\n",
    "\n",
    "First you can do start with making the data visualisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T05:20:56.208237Z",
     "start_time": "2020-01-13T05:20:56.076043Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(Put your analysis and conclusion here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Challange\n",
    "\n",
    "This will be not included to the scoring. \n",
    "\n",
    "- You can create additional analysis from the data.\n",
    "- Implement it to the dashboard with at `app.py` dan `index.html`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrap-capstone",
   "language": "python",
   "name": "scrap-capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
